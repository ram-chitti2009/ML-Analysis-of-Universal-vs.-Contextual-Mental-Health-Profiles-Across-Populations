{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fff8aac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSymptom Relationship Analysis: Testing Universal vs Context-Specific Patterns\\nTests whether symptom relationships (correlations) are consistent across datasets\\nThis addresses the fundamental flaw: K-matching is invalid, but symptom relationships are testable\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Symptom Relationship Analysis: Testing Universal vs Context-Specific Patterns\n",
    "Tests whether symptom relationships (correlations) are consistent across datasets\n",
    "This addresses the fundamental flaw: K-matching is invalid, but symptom relationships are testable\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e14f330c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f76bb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = {\n",
    "    'D1-Swiss': '/content/D1_Swiss_processed.csv',\n",
    "    'D2-Cultural': '/content/D2_Cultural_processed.csv',\n",
    "    'D3-Academic': '/content/D3_Academic_processed.csv',\n",
    "    'D4-Tech': '/content/D4_Tech_processed.csv',\n",
    "}\n",
    "\n",
    "FEATURE_COLUMNS = [\"Depression\", \"Anxiety\", \"Stress\", \"Burnout\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d840b229",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_all_correlations(df, feature_columns):\n",
    "    \"\"\"\n",
    "    Compute all pairwise correlations between features.\n",
    "    Returns a dict like: {\"Depression-Anxiety\": 0.62, ...}\n",
    "    \"\"\"\n",
    "    correlations = {}\n",
    "    \n",
    "    for i, feature1 in enumerate(feature_columns):\n",
    "        for j, feature2 in enumerate(feature_columns[i+1:], start=i+1):\n",
    "            \n",
    "            pair_name = f\"{feature1}-{feature2}\"\n",
    "            corr, _ = pearsonr(df[feature1], df[feature2])\n",
    "            \n",
    "            correlations[pair_name] = corr\n",
    "\n",
    "    return correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb42dde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_correlation_universality(comparison_df):\n",
    "    \"\"\"\n",
    "    Classify symptom relationships as Universal vs Context-Specific.\n",
    "    \n",
    "    Universal: Strong correlation (|r| > 0.3) AND consistent across datasets (CV < 0.30)\n",
    "    Contextual: Weak correlation (|r| ≤ 0.3) OR inconsistent across datasets (CV ≥ 0.30)\n",
    "    \n",
    "    Thresholds:\n",
    "    - 0.3: Cohen's medium effect size (established in psychology)\n",
    "    - CV < 0.30: Coefficient of variation < 30% = consistent\n",
    "    \"\"\"\n",
    "    universal_correlations = []\n",
    "    contextual_correlations = []\n",
    "    \n",
    "    for col in comparison_df.columns:\n",
    "        vals = comparison_df[col].values\n",
    "        vals = vals[~np.isnan(vals)]\n",
    "        \n",
    "        if len(vals) < 2:\n",
    "            continue\n",
    "        \n",
    "        mean_correlation = np.mean(vals)\n",
    "        std_correlation = np.std(vals)\n",
    "        # Use abs() to handle negative correlations correctly\n",
    "        cv_correlation = std_correlation / abs(mean_correlation) if mean_correlation != 0 else np.inf\n",
    "        \n",
    "        # Classify: Universal = strong and consistent\n",
    "        if abs(mean_correlation) > 0.3 and cv_correlation < 0.30:\n",
    "            universal_correlations.append({\n",
    "                'pair': col,\n",
    "                'mean_corr': mean_correlation,\n",
    "                'cv_corr': cv_correlation,\n",
    "                'std_corr': std_correlation,\n",
    "                'values': vals.tolist()\n",
    "            })\n",
    "        else:\n",
    "            contextual_correlations.append({\n",
    "                'pair': col,\n",
    "                'mean_corr': mean_correlation,\n",
    "                'std_corr': std_correlation,\n",
    "                'cv_corr': cv_correlation,\n",
    "                'values': vals.tolist()\n",
    "            })\n",
    "    \n",
    "    return universal_correlations, contextual_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1125522",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading datasets...\")\n",
    "all_data = {}\n",
    "for dataset_name, file_path in DATASETS.items():\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"{dataset_name} not found at {file_path}\")\n",
    "        continue\n",
    "    missing_features = [feature for feature in FEATURE_COLUMNS if feature not in df.columns]\n",
    "    if missing_features:\n",
    "        print(f\"Skipping {dataset_name} - missing required features: {', '.join(missing_features)}\")\n",
    "        continue\n",
    "    all_data[dataset_name] = df\n",
    "    print(f\"Loaded {dataset_name} with {len(df)} rows\")\n",
    "\n",
    "print(\"\\nComputing correlations...\")\n",
    "results = {}\n",
    "\n",
    "for dataset_name, df in all_data.items():\n",
    "    correlations = compute_all_correlations(df, FEATURE_COLUMNS)\n",
    "    results[dataset_name] = correlations\n",
    "\n",
    "# Create comparison dataframe\n",
    "comparison_df = pd.DataFrame(results).T\n",
    "comparison_df = comparison_df.round(3)\n",
    "\n",
    "print(\"\\nCorrelation Comparison Table:\")\n",
    "print(comparison_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406aec96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_effect_size(correlation):\n",
    "    \"\"\"Interpret correlation using Cohen's (1988) benchmarks.\"\"\"\n",
    "    abs_corr = abs(correlation)\n",
    "    if abs_corr < 0.1:\n",
    "        return \"negligible\"\n",
    "    elif abs_corr < 0.3:\n",
    "        return \"small\"\n",
    "    elif abs_corr < 0.5:\n",
    "        return \"medium\"\n",
    "    else:\n",
    "        return \"large\"\n",
    "\n",
    "# Analyze universality\n",
    "universal_correlations, contextual_correlations = analyze_correlation_universality(comparison_df)\n",
    "\n",
    "# Print results with effect size interpretation\n",
    "print(\"=\"*80)\n",
    "print(\"UNIVERSAL RELATIONSHIPS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Found {len(universal_correlations)} universal relationship(s):\\n\")\n",
    "\n",
    "for item in universal_correlations:\n",
    "    effect = interpret_effect_size(item['mean_corr'])\n",
    "    print(f\"  {item['pair']}:\")\n",
    "    print(f\"    Mean correlation: {item['mean_corr']:.3f} ({effect} effect)\")\n",
    "    print(f\"    CV: {item['cv_corr']:.3f} ({item['cv_corr']*100:.1f}%)\")\n",
    "    print(f\"    Std: {item['std_corr']:.3f}\")\n",
    "    print(f\"    Values across datasets: {[f'{v:.3f}' for v in item['values']]}\")\n",
    "    print()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"CONTEXTUAL RELATIONSHIPS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Found {len(contextual_correlations)} contextual relationship(s):\\n\")\n",
    "\n",
    "for item in contextual_correlations:\n",
    "    effect = interpret_effect_size(item['mean_corr'])\n",
    "    reason = []\n",
    "    if abs(item['mean_corr']) <= 0.3:\n",
    "        reason.append(\"weak correlation\")\n",
    "    if item['cv_corr'] >= 0.30:\n",
    "        reason.append(\"inconsistent\")\n",
    "    \n",
    "    print(f\"  {item['pair']}:\")\n",
    "    print(f\"    Mean correlation: {item['mean_corr']:.3f} ({effect} effect)\")\n",
    "    print(f\"    CV: {item['cv_corr']:.3f} ({item['cv_corr']*100:.1f}%)\")\n",
    "    print(f\"    Std: {item['std_corr']:.3f}\")\n",
    "    print(f\"    Values across datasets: {[f'{v:.3f}' for v in item['values']]}\")\n",
    "    print(f\"    Reason: {' OR '.join(reason) if reason else 'moderate'}\")\n",
    "    print()\n",
    "\n",
    "# Summary with hypothesis testing\n",
    "print(\"=\"*80)\n",
    "print(\"HYPOTHESIS TESTING SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "total_pairs = len(comparison_df.columns)\n",
    "universal_pct = len(universal_correlations) / total_pairs * 100\n",
    "contextual_pct = len(contextual_correlations) / total_pairs * 100\n",
    "\n",
    "print(f\"Total symptom pairs analyzed: {total_pairs}\")\n",
    "print(f\"Universal relationships: {len(universal_correlations)}/{total_pairs} ({universal_pct:.1f}%)\")\n",
    "print(f\"Contextual relationships: {len(contextual_correlations)}/{total_pairs} ({contextual_pct:.1f}%)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74196531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal visualization: Correlation comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "x = np.arange(len(comparison_df.columns))\n",
    "width = 0.2\n",
    "\n",
    "for i, dataset_name in enumerate(comparison_df.index):\n",
    "    ax.bar(x + i*width, comparison_df.loc[dataset_name], width, \n",
    "           label=dataset_name, alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Symptom Pairs', fontsize=11)\n",
    "ax.set_ylabel('Correlation (r)', fontsize=11)\n",
    "ax.set_title('Symptom Relationships Across Datasets', fontsize=12, fontweight='bold')\n",
    "ax.set_xticks(x + width * 1.5)\n",
    "ax.set_xticklabels(comparison_df.columns, rotation=45, ha='right')\n",
    "ax.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d48ea47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3befb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viz - Summary statistics table\n",
    "summary_data = []\n",
    "for item in universal_correlations + contextual_correlations:\n",
    "    effect = interpret_effect_size(item['mean_corr'])\n",
    "    classification = 'Universal' if item in universal_correlations else 'Contextual'\n",
    "    summary_data.append({\n",
    "        'Symptom Pair': item['pair'],\n",
    "        'Mean r': f\"{item['mean_corr']:.3f}\",\n",
    "        'Effect Size': effect,\n",
    "        'CV': f\"{item['cv_corr']:.3f}\",\n",
    "        'Std': f\"{item['std_corr']:.3f}\",\n",
    "        'Classification': classification\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_df = summary_df.sort_values('Classification', ascending=False)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SUMMARY STATISTICS TABLE\")\n",
    "print(\"=\"*80)\n",
    "print(summary_df.to_string(index=False))\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff226c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORT RESULTS FOR REPORT\n",
    "results_summary = {\n",
    "    'total_pairs': len(comparison_df.columns),\n",
    "    'universal_count': len(universal_correlations),\n",
    "    'contextual_count': len(contextual_correlations),\n",
    "    'universal_pairs': [item['pair'] for item in universal_correlations],\n",
    "    'contextual_pairs': [item['pair'] for item in contextual_correlations],\n",
    "    'comparison_table': comparison_df.to_dict(),\n",
    "    'universal_details': universal_correlations,\n",
    "    'contextual_details': contextual_correlations\n",
    "}\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"RESULTS EXPORTED\")\n",
    "print(\"=\"*80)\n",
    "print(\"Results stored in 'results_summary' dictionary\")\n",
    "print(\"Use this for your report/presentation\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f825b381",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972b4901",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61a3e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7acd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f7efe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
