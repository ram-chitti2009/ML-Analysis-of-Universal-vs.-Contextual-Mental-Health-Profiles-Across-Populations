{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ec763e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Dataset Balance Check\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "FEATURE_COLUMNS = [\"Depression\", \"Anxiety\", \"Stress\", \"Burnout\"]\n",
    "DATASETS = {\n",
    "    \"D1-Swiss\": Path(\"D1_Swiss_processed.csv\"),\n",
    "    \"D2-Cultural\": Path(\"D2_Cultural_processed.csv\"),\n",
    "    \"D3-Academic\": Path(\"D3_Academic_processed.csv\"),\n",
    "    \"D4-Tech\": Path(\"D4_Tech_processed.csv\"),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4ac5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check train/test balance for each dataset\n",
    "for dataset_name, dataset_path in DATASETS.items():\n",
    "    print(f\"\\n{dataset_name}:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    df = pd.read_csv(dataset_path)\n",
    "    feature_matrix = df[FEATURE_COLUMNS].values\n",
    "    \n",
    "    # Train/test split (matching Autoencoder.ipynb)\n",
    "    train_val_data, test_data = train_test_split(\n",
    "        feature_matrix, \n",
    "        test_size=0.2, \n",
    "        random_state=RANDOM_SEED\n",
    "    )\n",
    "    \n",
    "    train_df = pd.DataFrame(train_val_data, columns=FEATURE_COLUMNS)\n",
    "    test_df = pd.DataFrame(test_data, columns=FEATURE_COLUMNS)\n",
    "    \n",
    "    print(f\"Size: {len(feature_matrix)} total | Train: {len(train_val_data)} (80%) | Test: {len(test_data)} (20%)\")\n",
    "    \n",
    "    # Check if train/test distributions are similar\n",
    "    print(\"\\nTrain/Test Balance Check:\")\n",
    "    for col in FEATURE_COLUMNS:\n",
    "        train_mean = train_df[col].mean()\n",
    "        test_mean = test_df[col].mean()\n",
    "        abs_diff = abs(train_mean - test_mean)\n",
    "        \n",
    "        # Use absolute difference when mean is near zero, otherwise use percentage\n",
    "        if abs(train_mean) < 0.1:\n",
    "            # When mean is near zero, use absolute difference\n",
    "            status = \"✓\" if abs_diff < 0.05 else \"⚠\"\n",
    "            print(f\"  {col}: {status} Abs diff = {abs_diff:.4f} (Train: {train_mean:.4f}, Test: {test_mean:.4f})\")\n",
    "        else:\n",
    "            # When mean is not near zero, use percentage\n",
    "            mean_diff_pct = abs((train_mean - test_mean) / train_mean * 100)\n",
    "            status = \"✓\" if mean_diff_pct < 5 else \"⚠\"\n",
    "            print(f\"  {col}: {status} Mean diff = {mean_diff_pct:.2f}% | Abs diff = {abs_diff:.4f} (Train: {train_mean:.3f}, Test: {test_mean:.3f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68dd08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pragmatic Grid Search: Find optimal bin number for stratified splits\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "FEATURE_COLUMNS = [\"Depression\", \"Anxiety\", \"Stress\", \"Burnout\"]\n",
    "DATASETS = {\n",
    "    \"D1-Swiss\": Path(\"D1_Swiss_processed.csv\"),\n",
    "    \"D2-Cultural\": Path(\"D2_Cultural_processed.csv\"),\n",
    "    \"D3-Academic\": Path(\"D3_Academic_processed.csv\"),\n",
    "    \"D4-Tech\": Path(\"D4_Tech_processed.csv\"),\n",
    "}\n",
    "MAX_BINS_TO_TRY = 6\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"GRID SEARCH: Finding Optimal Bin Number for Stratified Splits\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Testing bins from 2 to {MAX_BINS_TO_TRY}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "all_results = {}\n",
    "\n",
    "for dataset_name, dataset_path in DATASETS.items():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"{dataset_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    df = pd.read_csv(dataset_path)\n",
    "    feature_matrix = df[FEATURE_COLUMNS].values\n",
    "    dataset_size = len(feature_matrix)\n",
    "\n",
    "    print(f\"Dataset size: {dataset_size}\")\n",
    "    best_bins = None\n",
    "    best_imbalance = float('inf')\n",
    "    best_results = None\n",
    "    results_list = []\n",
    "    \n",
    "    for n_bins in range(2, MAX_BINS_TO_TRY + 1):\n",
    "        try:\n",
    "            df_binned = df.copy()\n",
    "            for col in FEATURE_COLUMNS:\n",
    "                df_binned[f'{col}_bin'] = pd.qcut(\n",
    "                    df[col], \n",
    "                    q=n_bins, \n",
    "                    labels=False, \n",
    "                    duplicates='drop'\n",
    "                )\n",
    "            # Create stratification label\n",
    "            df_binned['stratify_label'] = df_binned[[f'{col}_bin' for col in FEATURE_COLUMNS]].apply(\n",
    "                lambda x: '_'.join(x.astype(str)), axis=1\n",
    "            )\n",
    "\n",
    "            # Check if stratification is possible\n",
    "            stratum_counts = df_binned['stratify_label'].value_counts()\n",
    "            min_stratum_size = stratum_counts.min()\n",
    "\n",
    "            if min_stratum_size < 2:\n",
    "                print(f\"  {n_bins} bins: ✗ Failed (min stratum size = {min_stratum_size})\")\n",
    "                results_list.append({\n",
    "                    'bins': n_bins,\n",
    "                    'status': 'Failed',\n",
    "                    'reason': f'Min stratum size = {min_stratum_size}'\n",
    "                })\n",
    "                continue\n",
    "\n",
    "            # Perform stratified split\n",
    "            train_val_data, test_data = train_test_split(\n",
    "                feature_matrix, \n",
    "                test_size=0.2, \n",
    "                random_state=RANDOM_SEED,\n",
    "                stratify=df_binned['stratify_label']\n",
    "            )\n",
    "\n",
    "            train_df = pd.DataFrame(train_val_data, columns=FEATURE_COLUMNS)\n",
    "            test_df = pd.DataFrame(test_data, columns=FEATURE_COLUMNS)\n",
    "\n",
    "            total_imbalance = 0\n",
    "            max_imbalance = 0\n",
    "            feature_imbalances = []\n",
    "\n",
    "            for col in FEATURE_COLUMNS:\n",
    "                train_mean = train_df[col].mean()\n",
    "                test_mean = test_df[col].mean()\n",
    "                abs_diff = abs(train_mean - test_mean)\n",
    "                \n",
    "                if abs(train_mean) < 0.1:\n",
    "                    normalized_diff = abs_diff\n",
    "                    metric = \"abs\"\n",
    "                else:\n",
    "                    normalized_diff = abs((train_mean - test_mean) / train_mean * 100)\n",
    "                    metric = \"pct\"\n",
    "                \n",
    "                feature_imbalances.append({\n",
    "                    'feature': col,\n",
    "                    'train_mean': train_mean,\n",
    "                    'test_mean': test_mean,\n",
    "                    'diff': normalized_diff,\n",
    "                    'metric': metric\n",
    "                })\n",
    "                \n",
    "                total_imbalance += normalized_diff\n",
    "                max_imbalance = max(max_imbalance, normalized_diff)\n",
    "            \n",
    "            avg_imbalance = total_imbalance / len(FEATURE_COLUMNS)\n",
    "            \n",
    "            print(f\"  {n_bins} bins: ✓ Total imbalance = {total_imbalance:.2f} | \"\n",
    "                  f\"Max = {max_imbalance:.2f} | Avg = {avg_imbalance:.2f}\")\n",
    "            \n",
    "            results_list.append({\n",
    "                'bins': n_bins,\n",
    "                'status': 'Success',\n",
    "                'total_imbalance': total_imbalance,\n",
    "                'avg_imbalance': avg_imbalance,\n",
    "                'max_imbalance': max_imbalance,\n",
    "                'feature_imbalances': feature_imbalances\n",
    "            })\n",
    "            \n",
    "            # Track best result\n",
    "            if total_imbalance < best_imbalance:\n",
    "                best_imbalance = total_imbalance\n",
    "                best_bins = n_bins\n",
    "                best_results = {\n",
    "                    'train_df': train_df,\n",
    "                    'test_df': test_df,\n",
    "                    'feature_imbalances': feature_imbalances,\n",
    "                    'total_imbalance': total_imbalance,\n",
    "                    'avg_imbalance': avg_imbalance,\n",
    "                    'max_imbalance': max_imbalance\n",
    "                }\n",
    "                \n",
    "        except (ValueError, KeyError) as e:\n",
    "            error_msg = str(e)\n",
    "            if \"least populated class\" in error_msg:\n",
    "                reason = \"Some strata have < 2 samples\"\n",
    "            else:\n",
    "                reason = error_msg[:40]\n",
    "            \n",
    "            print(f\"  {n_bins} bins: ✗ Failed ({reason})\")\n",
    "            results_list.append({\n",
    "                'bins': n_bins,\n",
    "                'status': 'Failed',\n",
    "                'reason': reason\n",
    "            })\n",
    "            continue\n",
    "    \n",
    "    # Summary for this dataset\n",
    "    print(f\"\\n  Summary:\")\n",
    "    if best_bins is not None:\n",
    "        print(f\"  ✓ Best: {best_bins} bins (Total imbalance = {best_imbalance:.2f})\")\n",
    "        print(f\"\\n  Best configuration details ({best_bins} bins):\")\n",
    "        for fi in best_results['feature_imbalances']:\n",
    "            if fi['metric'] == 'abs':\n",
    "                status = \"✓\" if fi['diff'] < 0.05 else \"⚠\"\n",
    "                print(f\"    {fi['feature']}: {status} {fi['diff']:.4f} abs diff \"\n",
    "                      f\"(Train: {fi['train_mean']:.4f}, Test: {fi['test_mean']:.4f})\")\n",
    "            else:\n",
    "                status = \"✓\" if fi['diff'] < 5 else \"⚠\"\n",
    "                print(f\"    {fi['feature']}: {status} {fi['diff']:.2f}% diff \"\n",
    "                      f\"(Train: {fi['train_mean']:.3f}, Test: {fi['test_mean']:.3f})\")\n",
    "    else:\n",
    "        print(f\"  ✗ No successful configuration found\")\n",
    "    \n",
    "    # Results table\n",
    "    print(f\"\\n  All results:\")\n",
    "    print(f\"  {'Bins':<6} {'Status':<10} {'Total Imbalance':<15} {'Avg Imbalance':<15} {'Max Imbalance':<15}\")\n",
    "    print(f\"  {'-'*6} {'-'*10} {'-'*15} {'-'*15} {'-'*15}\")\n",
    "    for r in results_list:\n",
    "        if r['status'] == 'Success':\n",
    "            print(f\"  {r['bins']:<6} {r['status']:<10} {r['total_imbalance']:<15.2f} \"\n",
    "                  f\"{r['avg_imbalance']:<15.2f} {r['max_imbalance']:<15.2f}\")\n",
    "        else:\n",
    "            print(f\"  {r['bins']:<6} {r['status']:<10} {'N/A':<15} {'N/A':<15} {'N/A':<15}\")\n",
    "    \n",
    "    all_results[dataset_name] = {\n",
    "        'best_bins': best_bins,\n",
    "        'best_imbalance': best_imbalance,\n",
    "        'best_results': best_results,\n",
    "        'all_results': results_list\n",
    "    }\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"GRID SEARCH COMPLETE\")\n",
    "print(f\"{'='*80}\")\n",
    "print(\"\\nRecommendations:\")\n",
    "for dataset_name, result in all_results.items():\n",
    "    if result['best_bins']:\n",
    "        print(f\"  {dataset_name}: Use {result['best_bins']} bins \"\n",
    "              f\"(Imbalance: {result['best_imbalance']:.2f})\")\n",
    "    else:\n",
    "        print(f\"  {dataset_name}: No working configuration found\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e836f5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edab0527",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7d2044",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ca6c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777d1cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055242da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee006e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11694358",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
