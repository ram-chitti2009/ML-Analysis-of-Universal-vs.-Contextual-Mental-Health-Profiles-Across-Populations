{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dca6c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in c:\\users\\venka\\desktop\\mental-health-profiling\\venv\\lib\\site-packages (1.7.4.5)\n",
      "Requirement already satisfied: opendatasets in c:\\users\\venka\\desktop\\mental-health-profiling\\venv\\lib\\site-packages (0.1.22)\n",
      "Requirement already satisfied: bleach in c:\\users\\venka\\desktop\\mental-health-profiling\\venv\\lib\\site-packages (from kaggle) (6.3.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in c:\\users\\venka\\desktop\\mental-health-profiling\\venv\\lib\\site-packages (from kaggle) (2025.10.5)\n",
      "Requirement already satisfied: charset-normalizer in c:\\users\\venka\\desktop\\mental-health-profiling\\venv\\lib\\site-packages (from kaggle) (3.4.4)\n",
      "Requirement already satisfied: idna in c:\\users\\venka\\desktop\\mental-health-profiling\\venv\\lib\\site-packages (from kaggle) (3.11)\n",
      "Requirement already satisfied: protobuf in c:\\users\\venka\\desktop\\mental-health-profiling\\venv\\lib\\site-packages (from kaggle) (6.33.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\venka\\desktop\\mental-health-profiling\\venv\\lib\\site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\venka\\desktop\\mental-health-profiling\\venv\\lib\\site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: requests in c:\\users\\venka\\desktop\\mental-health-profiling\\venv\\lib\\site-packages (from kaggle) (2.32.5)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in c:\\users\\venka\\desktop\\mental-health-profiling\\venv\\lib\\site-packages (from kaggle) (80.9.0)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\venka\\desktop\\mental-health-profiling\\venv\\lib\\site-packages (from kaggle) (1.17.0)\n",
      "Requirement already satisfied: text-unidecode in c:\\users\\venka\\desktop\\mental-health-profiling\\venv\\lib\\site-packages (from kaggle) (1.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\venka\\desktop\\mental-health-profiling\\venv\\lib\\site-packages (from kaggle) (4.67.1)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in c:\\users\\venka\\desktop\\mental-health-profiling\\venv\\lib\\site-packages (from kaggle) (2.5.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\venka\\desktop\\mental-health-profiling\\venv\\lib\\site-packages (from kaggle) (0.5.1)\n",
      "Requirement already satisfied: click in c:\\users\\venka\\desktop\\mental-health-profiling\\venv\\lib\\site-packages (from opendatasets) (8.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\venka\\desktop\\mental-health-profiling\\venv\\lib\\site-packages (from click->opendatasets) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install required packages for working with Kaggle datasets\n",
    "%pip install kaggle opendatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71b9658a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/thedevastator/medical-student-mental-health\n",
      "Dataset downloaded successfully!\n",
      "Dataset downloaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import kaggle\n",
    "import os \n",
    "kaggle.api.dataset_download_files('osmi/mental-health-in-tech-survey', \n",
    "                                  path='./data', \n",
    "                                  unzip=True)\n",
    "\n",
    "print(\"Dataset downloaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d5e2895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in the data directory:\n",
      "- ./data\\Codebook Carrard et al. 2022 MedTeach.csv\n",
      "- ./data\\Data Carrard et al. 2022 MedTeach.csv\n",
      "\n",
      "Trying to load: ./data\\Codebook Carrard et al. 2022 MedTeach.csv\n",
      "Skipping codebook file\n",
      "\n",
      "Trying to load: ./data\\Data Carrard et al. 2022 MedTeach.csv\n",
      "Successfully loaded: ./data\\Data Carrard et al. 2022 MedTeach.csv\n",
      "Shape: (886, 20)\n",
      "Columns: ['id', 'age', 'year', 'sex', 'glang', 'part', 'job', 'stud_h', 'health', 'psyt', 'jspe', 'qcae_cog', 'qcae_aff', 'amsp', 'erec_mean', 'cesd', 'stai_t', 'mbi_ex', 'mbi_cy', 'mbi_ea']\n",
      "\n",
      "First 5 rows:\n",
      "   id  age  year  sex  glang  part  job  stud_h  health  psyt  jspe  qcae_cog  \\\n",
      "0   2   18     1    1    120     1    0      56       3     0    88        62   \n",
      "1   4   26     4    1      1     1    0      20       4     0   109        55   \n",
      "2   9   21     3    2      1     0    0      36       3     0   106        64   \n",
      "3  10   21     2    2      1     0    1      51       5     0   101        52   \n",
      "4  13   21     3    1      1     1    0      22       4     0   102        58   \n",
      "\n",
      "   qcae_aff  amsp  erec_mean  cesd  stai_t  mbi_ex  mbi_cy  mbi_ea  \n",
      "0        27    17   0.738095    34      61      17      13      20  \n",
      "1        37    22   0.690476     7      33      14      11      26  \n",
      "2        39    17   0.690476    25      73      24       7      23  \n",
      "3        33    18   0.833333    17      48      16      10      21  \n",
      "4        28    21   0.690476    14      46      22      14      23  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os \n",
    "\n",
    "os.makedirs(\"./data\", exist_ok=True)\n",
    "\n",
    "data_files = glob.glob('./data/*')\n",
    "print(\"Files in the data directory:\")\n",
    "for file in data_files:\n",
    "    print(f\"- {file}\")\n",
    "\n",
    "df = None\n",
    "for file in data_files:\n",
    "    if file.endswith('.csv'):\n",
    "        try:\n",
    "            print(f\"\\nTrying to load: {file}\")\n",
    "            \n",
    "            if 'codebook' in file.lower():\n",
    "                print(\"Skipping codebook file\")\n",
    "                continue\n",
    "            elif 'data' in file.lower():\n",
    "                df = pd.read_csv(file, encoding='utf-8', on_bad_lines='skip')\n",
    "                print(f\"Successfully loaded: {file}\")\n",
    "                print(f\"Shape: {df.shape}\")\n",
    "                print(f\"Columns: {df.columns.tolist()}\")\n",
    "                \n",
    "            else:\n",
    "                df = pd.read_csv(file, encoding='utf-8', on_bad_lines='skip')\n",
    "                print(f\"Successfully loaded: {file}\")\n",
    "                print(f\"Shape: {df.shape}\")\n",
    "                print(f\"Columns: {df.columns.tolist()}\")\n",
    "                \n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "if df is not None:\n",
    "    print(\"\\nFirst 5 rows:\")\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(\"No dataset could be loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d4532a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded D1-Swiss dataset with shape: (886, 20)\n",
      "File not found for D2-Cultural: Student Mental health (1).csv\n",
      "Loaded D3-Academic dataset with shape: (27901, 18)\n",
      "Converting categorical column Stress to numerical in D3-Academic\n",
      "Loaded D4-Tech dataset with shape: (1259, 27)\n",
      "Converting categorical column Depression to numerical in D4-Tech\n",
      "Converting categorical column Anxiety to numerical in D4-Tech\n",
      "Converting categorical column Burnout to numerical in D4-Tech\n",
      "\n",
      "Datasets with missing files or errors:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\venka\\AppData\\Local\\Temp\\ipykernel_8932\\1049683277.py:56: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[col] = df[col].astype(str).str.lower().replace({\n",
      "C:\\Users\\venka\\AppData\\Local\\Temp\\ipykernel_8932\\1049683277.py:83: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_combined[feature].fillna(mean_value, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combined dataset shape: (30046, 56)\n",
      "\n",
      "Data Cleaning: Handling missing values\n",
      "\n",
      "Normalizing Universal Features using Z-score normalization\n",
      "Normalization complete. Scaler saved as 'universal_features_scaler.joblib'.\n",
      "\n",
      "Fused dataset saved as 'fused_mental_health_dataset.csv'\n",
      "\n",
      "D1-Swiss dataset shape after processing: (886, 56)\n",
      "D1-Swiss processed dataset saved as 'D1_Swiss_processed.csv'\n",
      "\n",
      "Data processing complete.\n",
      "\n",
      "Fused dataset saved as 'fused_mental_health_dataset.csv'\n",
      "\n",
      "D1-Swiss dataset shape after processing: (886, 56)\n",
      "D1-Swiss processed dataset saved as 'D1_Swiss_processed.csv'\n",
      "\n",
      "Data processing complete.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "FILE_PATHS = {\n",
    "    'D1-Swiss': 'Data Carrard et al. 2022 MedTeach.csv', \n",
    "    'D2-Cultural': 'Student Mental health (1).csv',     \n",
    "    'D3-Academic': 'student_depression_dataset.csv',    \n",
    "    'D4-Tech': 'survey.csv'                             \n",
    "}\n",
    "COLUMN_MAPPING = {\n",
    "    # D1-Swiss: accurate mappings based on validated scales\n",
    "    'D1-Swiss':      {'cesd': 'Depression', 'stai_t': 'Anxiety', 'mbi_ex': 'Burnout', 'mbi_cy': 'Stress', 'psyt': 'PSYT_Therapy_Use'}, \n",
    "    \n",
    "    # D2-Cultural: Weak Proxies used for a \"Fragmentation Stress Test\"\n",
    "    'D2-Cultural':   {'Do you have Depression?': 'Depression', 'Do you have Anxiety?': 'Anxiety', 'Do you have Panic attack?': 'Burnout', 'Your current year of Study': 'Stress'}, \n",
    "    \n",
    "    'D3-Academic':   {'Depression': 'Depression', 'Academic Pressure': 'Anxiety', 'Study Satisfaction': 'Burnout', 'Financial Stress': 'Stress'}, \n",
    "    \n",
    "    'D4-Tech':       {'mental_health_consequence': 'Depression', 'work_interfere': 'Anxiety', 'leave': 'Burnout', 'Age': 'Stress', 'treatment': 'H3_Tech_Validation'}, \n",
    "}\n",
    "\n",
    "#mapping : translates raw column names into 4 Universal Features\n",
    "UNIVERSAL_FEATURES = ['Depression', 'Anxiety', 'Burnout', 'Stress']\n",
    "\n",
    "all_data_frames = []\n",
    "missing_files = []\n",
    "\n",
    "for source_name, file_path in FILE_PATHS.items():\n",
    "    try:\n",
    "        df = pd.read_csv(os.path.join('./data', file_path), encoding='utf-8', on_bad_lines='skip')\n",
    "        print(f\"Loaded {source_name} dataset with shape: {df.shape}\")\n",
    "\n",
    "        current_mapping = COLUMN_MAPPING[source_name]\n",
    "        missing_cols = [src for src in current_mapping.keys() if src not in df.columns]\n",
    "        if missing_cols:\n",
    "            print(f\"ERROR: Missing crucial columns in {file_path}: {missing_cols}\")\n",
    "            missing_files.append(file_path)\n",
    "            continue\n",
    "        df = df.rename(columns=current_mapping)\n",
    "\n",
    "        selected_columns = UNIVERSAL_FEATURES.copy()\n",
    "\n",
    "        if 'PYST_Therapy_Use' in current_mapping.values():\n",
    "            selected_columns.append('PSYT_Therapy_Use')\n",
    "        \n",
    "        df_selected = df[selected_columns]\n",
    "        df['Source_Group'] = source_name\n",
    "\n",
    "        #Convert categorical to numerical where necessary\n",
    "        for col in UNIVERSAL_FEATURES:\n",
    "            if df[col].dtype == 'object': \n",
    "                print(f\"Converting categorical column {col} to numerical in {source_name}\")\n",
    "                df[col] = df[col].astype(str).str.lower().replace({\n",
    "                     'yes': 1, 'no': 0, 'often': 1, 'rarely': 0, 'sometimes': 0.5, 'maybe': 0.5,\n",
    "                     'most of the time': 1, 'never': 0, 'always': 1, 'not sure': 0.5,\n",
    "                     'high': 1, 'low': 0, 'medium': 0.5,\n",
    "                     'somewhat easy': 0.5, 'somewhat difficult': 0.5, 'very difficult': 1, 'very easy': 0\n",
    "                })\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "                \n",
    "        all_data_frames.append(df)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found for {source_name}: {file_path}\")\n",
    "        missing_files.append(source_name)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {source_name} dataset: {str(e)}\")\n",
    "        missing_files.append(source_name)\n",
    "\n",
    "if missing_files:\n",
    "    print(\"\\nDatasets with missing files or errors:\")\n",
    "\n",
    "df_combined = pd.concat(all_data_frames, ignore_index=True)\n",
    "print(f\"\\nCombined dataset shape: {df_combined.shape}\")\n",
    "\n",
    "#Data Cleaning: Handle missing values by dropping rows with any NaNs in Universal Features\n",
    "print(\"\\nData Cleaning: Handling missing values\")\n",
    "for feature in UNIVERSAL_FEATURES:\n",
    "    mean_value = df_combined[feature].mean()\n",
    "    df_combined[feature].fillna(mean_value, inplace=True)\n",
    "\n",
    "#Z Score Normalization\n",
    "#Using StandardScaler from sklearn to normalize the Universal Features\n",
    "print(\"\\nNormalizing Universal Features using Z-score normalization\")\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df_combined[UNIVERSAL_FEATURES] = scaler.fit_transform(df_combined[UNIVERSAL_FEATURES])\n",
    "joblib.dump(scaler, 'universal_features_scaler.joblib')\n",
    "print(\"Normalization complete. Scaler saved as 'universal_features_scaler.joblib'.\")\n",
    "\n",
    "#Saving the fused dataframe\n",
    "df_combined.to_csv('fused_mental_health_dataset.csv', index=False)\n",
    "print(\"\\nFused dataset saved as 'fused_mental_health_dataset.csv'\")\n",
    "\n",
    "df_d1 = df_combined[df_combined['Source_Group'] == 'D1-Swiss']\n",
    "print(f\"\\nD1-Swiss dataset shape after processing: {df_d1.shape}\")\n",
    "df_d1.to_csv('D1_Swiss_processed.csv', index=False)\n",
    "print(\"D1-Swiss processed dataset saved as 'D1_Swiss_processed.csv'\")\n",
    "print(\"\\nData processing complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
